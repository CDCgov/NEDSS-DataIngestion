<configuration>
<!-- ENV -->
<variable resource="application.yaml" />

<!-- Appender for Console -->
<appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
</appender>

<!-- Appender for File -->
<appender name="FILE" class="ch.qos.logback.core.FileAppender">
    <file>${LOG_PATH}/report-service.log</file>
    <encoder>
        <pattern>%d %-5level [%thread] %logger : %msg%n</pattern>
    </encoder>
</appender>

<appender name="DYNAMIC_FILE" class="gov.cdc.dataingestion.config.LogDynamicFileAppenderConfig">
    <logFilePath>${LOG_PATH}/kafka_dlt_error-%d{yyyy-MM-dd_HH-mm-ss}.log</logFilePath>
    <append>true</append>
    <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    <filter class="ch.qos.logback.classic.filter.LevelFilter">
        <level>ERROR</level>
        <onMatch>ACCEPT</onMatch>
        <onMismatch>DENY</onMismatch>
    </filter>
    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
        <fileNamePattern>${LOG_PATH}/kafka_dlt_error-%d{yyyy-MM-dd_HH-mm-ss}.log</fileNamePattern>
        <maxFileSize>100MB</maxFileSize> <!-- Maximum size of each log file -->
        <maxHistory>30</maxHistory> <!-- Number of old log files to keep -->
        <totalSizeCap>1GB</totalSizeCap> <!-- Maximum total size of log files -->
    </rollingPolicy>
    <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
        <maxFileSize>100MB</maxFileSize> <!-- Size threshold to trigger log file rolling -->
    </triggeringPolicy>
</appender>

<!-- Loggers -->
<logger name="gov.cdc.dataingestion.kafka.integration.service.KafkaConsumerService" level="INFO">
    <appender-ref ref="DYNAMIC_FILE" />
</logger>

<logger name="com.apps.restfulApp.api.controller" level="INFO">
    <appender-ref ref="FILE" />
</logger>

<root level="INFO">
    <appender-ref ref="CONSOLE" />
</root>
</configuration>